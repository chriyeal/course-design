import os
import torch
import torchvision.models as models
from torch import nn
from torchvision import transforms
from torch.utils.data import DataLoader, Dataset
import torch.optim as optim
from PIL import Image

# ç±»åˆ«åç§°ï¼ˆä¸éœ€æ±‚ä¸€è‡´ï¼Œå®šä¹‰ä¸ºå…¨å±€å˜é‡ï¼‰
classes = [
    "Daffodil", "Snowdrop", "Lily Valley", "Bluebell",
    "Crocus", "Iris", "Tigerlily", "Tulip",
    "Fritillary", "Sunflower", "Daisy", "Colts' Foot",
    "Dandelion", "Cowslip", "Buttercup", "Windflower", "Pansy"
]


# -------------------------- 1. æ„å»ºæ¨¡å‹ï¼ˆResNet18 + è§£å†»éƒ¨åˆ†å±‚ï¼‰ --------------------------
def build_model(num_classes=17):
    # ä½¿ç”¨æ–°ç‰ˆAPIåŠ è½½é¢„è®­ç»ƒæ¨¡å‹
    from torchvision.models import resnet18, ResNet18_Weights
    model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)

    # å†»ç»“éƒ¨åˆ†ç‰¹å¾å±‚ï¼ˆåªè§£å†»åå‡ å±‚ï¼Œä¾¿äºå°æ•°æ®é›†å¾®è°ƒï¼‰
    for param in model.parameters():
        param.requires_grad = False  # å…ˆå…¨éƒ¨å†»ç»“

    # è§£å†»åä¸‰å±‚å·ç§¯å—å’Œåˆ†ç±»å¤´
    for param in model.layer3.parameters():
        param.requires_grad = True  # è§£å†»layer3
    for param in model.layer4.parameters():
        param.requires_grad = True  # è§£å†»layer4
    for param in model.fc.parameters():
        param.requires_grad = True  # è§£å†»åˆ†ç±»å¤´

    # æ›¿æ¢åˆ†ç±»å¤´ï¼ˆå‡å°‘ç»´åº¦ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆï¼‰
    model.fc = nn.Sequential(
        nn.Linear(model.fc.in_features, 256),  # å‡å°‘å…¨è¿æ¥å±‚ç»´åº¦
        nn.ReLU(),
        nn.Dropout(0.3),  # å¢åŠ Dropouté˜²æ­¢è¿‡æ‹Ÿåˆ
        nn.Linear(256, num_classes)
    )
    return model


# -------------------------- 2. è‡ªå®šä¹‰æ•°æ®é›†ç±»ï¼ˆä¿®æ­£å‚æ•°åï¼‰ --------------------------
class OrderedFlowerDataset(Dataset):
    def __init__(self, root_dir, transform=None, class_order=None):
        self.root_dir = root_dir  # æ­£ç¡®å‚æ•°åï¼šroot_dir
        self.transform = transform
        self.class_order = class_order or classes  # ä½¿ç”¨å…¨å±€classesåˆ—è¡¨

        # åˆ›å»ºç±»åˆ«åˆ°ç´¢å¼•çš„æ˜ å°„ï¼ˆæŒ‰class_orderé¡ºåºï¼‰
        self.class_to_idx = {cls: i for i, cls in enumerate(self.class_order)}

        # æ”¶é›†æ‰€æœ‰å›¾åƒè·¯å¾„å’Œæ ‡ç­¾
        self.samples = []
        for cls in self.class_order:
            cls_dir = os.path.join(root_dir, cls)
            if not os.path.exists(cls_dir):
                continue  # è·³è¿‡ä¸å­˜åœ¨çš„ç±»åˆ«ï¼ˆé˜²æ­¢è¯¯æ“ä½œï¼‰
            for img_name in os.listdir(cls_dir):
                if img_name.lower().endswith(('.jpg', '.jpeg', '.png')):
                    img_path = os.path.join(cls_dir, img_name)
                    self.samples.append((img_path, self.class_to_idx[cls]))

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        img_path, label = self.samples[idx]
        image = Image.open(img_path).convert('RGB')

        if self.transform:
            image = self.transform(image)

        return image, label


# -------------------------- 3. è®­ç»ƒ/éªŒè¯æµç¨‹ --------------------------
def train_epoch(model, train_loader, criterion, optimizer, device):
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0

    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()
        _, predicted = outputs.max(1)
        total += labels.size(0)
        correct += predicted.eq(labels).sum().item()

    return running_loss / len(train_loader), 100. * correct / total


def val_epoch(model, val_loader, criterion, device):
    model.eval()
    running_loss = 0.0
    correct = 0
    total = 0

    with torch.no_grad():
        for images, labels in val_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            loss = criterion(outputs, labels)

            running_loss += loss.item()
            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()

    return running_loss / len(val_loader), 100. * correct / total


# -------------------------- 4. ä¸»è®­ç»ƒé€»è¾‘ --------------------------
if __name__ == "__main__":
    # æ•°æ®é›†è·¯å¾„ï¼ˆä¸åˆ’åˆ†è„šæœ¬ä¸€è‡´ï¼‰
    data_root = r"F:\A.æœºå™¨å­¦ä¹ \è¯¾è®¾\17flowers"

    # å¢å¼ºæ•°æ®é¢„å¤„ç†ï¼ˆå¢åŠ æ—‹è½¬ã€é¢œè‰²æŠ–åŠ¨ç­‰ï¼‰
    data_transform = {
        "train": transforms.Compose([
            transforms.RandomResizedCrop(224),
            transforms.RandomHorizontalFlip(),
            transforms.RandomRotation(20),  # å¢åŠ éšæœºæ—‹è½¬
            transforms.ColorJitter(brightness=0.2, contrast=0.2),  # é¢œè‰²æŠ–åŠ¨
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ]),
        "val": transforms.Compose([
            transforms.Resize(256),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])
    }

    # ä½¿ç”¨è‡ªå®šä¹‰æ•°æ®é›†ç±»åŠ è½½æ•°æ®ï¼ˆå‚æ•°åä¿®æ­£ä¸ºroot_dirï¼‰
    train_dataset = OrderedFlowerDataset(
        root_dir=os.path.join(data_root, "train"),  # æ­£ç¡®å‚æ•°åï¼šroot_dir
        transform=data_transform["train"],
        class_order=classes
    )
    val_dataset = OrderedFlowerDataset(
        root_dir=os.path.join(data_root, "val"),  # æ­£ç¡®å‚æ•°åï¼šroot_dir
        transform=data_transform["val"],
        class_order=classes
    )

    # æ„å»º DataLoaderï¼ˆå°æ‰¹æ¬¡é€‚é…é›†æˆæ˜¾å¡ï¼‰
    batch_size = 4  # é›†æˆæ˜¾å¡ç”¨æ›´å°æ‰¹æ¬¡
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)

    # åˆå§‹åŒ–æ¨¡å‹ã€æŸå¤±ã€ä¼˜åŒ–å™¨
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = build_model().to(device)
    criterion = nn.CrossEntropyLoss()

    # ä»…ä¼˜åŒ–è§£å†»çš„å±‚ï¼ˆlayer3ã€layer4å’Œfcï¼‰
    optimizer = optim.AdamW(
        [p for p in model.parameters() if p.requires_grad],
        lr=5e-5,  # å°å­¦ä¹ ç‡é˜²æ­¢è¿‡æ‹Ÿåˆ
        weight_decay=0.01  # æƒé‡è¡°å‡æ­£åˆ™åŒ–
    )

    # å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼ˆç§»é™¤verboseå‚æ•°ï¼Œä¿®å¤å…¼å®¹æ€§é—®é¢˜ï¼‰
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, mode='min', factor=0.5, patience=3
    )

    # è®­ç»ƒå‚æ•°
    num_epochs = 10  # å¢åŠ è®­ç»ƒè½®æ•°
    best_acc = 0.0
    best_epoch = 0

    print(f"ğŸ”§ è®­ç»ƒè®¾å¤‡: {device} | æ‰¹æ¬¡å¤§å°: {batch_size} | ç±»åˆ«æ•°: {len(train_dataset.class_order)}")
    print("==================== å¼€å§‹è®­ç»ƒ ====================")

    for epoch in range(num_epochs):
        # è®­ç»ƒ1è½®
        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)

        # éªŒè¯
        val_loss, val_acc = val_epoch(model, val_loader, criterion, device)

        # è°ƒæ•´å­¦ä¹ ç‡
        scheduler.step(val_loss)

        # ä¿å­˜æœ€ä¼˜æ¨¡å‹
        if val_acc > best_acc:
            best_acc = val_acc
            best_epoch = epoch + 1
            torch.save(model.state_dict(), "best_model.pth")
            print(f"ğŸ“¦ æ¨¡å‹æ›´æ–°ï¼šEpoch {epoch + 1} éªŒè¯å‡†ç¡®ç‡ {val_acc:.2f}%")

        # æ‰“å°æ—¥å¿—
        print(f"Epoch {epoch + 1}/{num_epochs}")
        print(f"  è®­ç»ƒæŸå¤±: {train_loss:.4f} | è®­ç»ƒå‡†ç¡®ç‡: {train_acc:.2f}%")
        print(f"  éªŒè¯æŸå¤±: {val_loss:.4f} | éªŒè¯å‡†ç¡®ç‡: {val_acc:.2f}%")
        print("-" * 50)

    print(f"==================== è®­ç»ƒç»“æŸ ===================")
    print(f"ğŸ’¯ æœ€ä¼˜éªŒè¯å‡†ç¡®ç‡: {best_acc:.2f}% (Epoch {best_epoch}) | æ¨¡å‹å·²ä¿å­˜ä¸º best_model.pth")
